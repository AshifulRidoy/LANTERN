torch>=2.0.0
transformers>=4.35.0
tokenizers>=0.15.0
datasets>=2.14.0
accelerate>=0.24.0

# Model fine-tuning and optimization
peft>=0.6.0
bitsandbytes>=0.41.0
trl>=0.7.0

# LangChain and agent orchestration
langchain>=0.1.0
langchain-community>=0.0.10
langchain-core>=0.1.0

# API and web framework
fastapi>=0.104.0
uvicorn>=0.24.0
pydantic>=2.5.0

# Data processing and utilities
pandas>=2.1.0
numpy>=1.24.0
scikit-learn>=1.3.0
tqdm>=4.66.0

# Logging and monitoring
wandb>=0.16.0
tensorboard>=2.15.0

# Evaluation and explainability
captum>=0.6.0
shap>=0.43.0
alibi>=0.9.0

# Optional: Additional model serving
vllm>=0.2.0  # For optimized LLaMA serving
#text-generation-inference  # Alternative serving option

# Development and testing
pytest>=7.4.0
pytest-asyncio>=0.21.0
black>=23.0.0
flake8>=6.0.0
mypy>=1.7.0

# Jupyter and notebooks (for development)
jupyter>=1.0.0
ipywidgets>=8.1.0

# Additional utilities
python-multipart>=0.0.6  # For FastAPI file uploads
httpx>=0.25.0  # For async HTTP requests
aiofiles>=23.2.0  # For async file operations
python-dotenv>=1.0.0  # For environment variables

# GPU utilities (optional)
nvidia-ml-py3>=7.352.0  # For GPU monitoring

python-dotenv
